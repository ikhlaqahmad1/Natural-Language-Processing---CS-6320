{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7379779,"sourceType":"datasetVersion","datasetId":4288635}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-06T16:32:47.101049Z","iopub.execute_input":"2024-05-06T16:32:47.101733Z","iopub.status.idle":"2024-05-06T16:32:47.113330Z","shell.execute_reply.started":"2024-05-06T16:32:47.101703Z","shell.execute_reply":"2024-05-06T16:32:47.112485Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"/kaggle/input/ai-vs-human-text/AI_Human.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load data from CSV\ndf = pd.read_csv('/kaggle/input/ai-vs-human-text/AI_Human.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:32:51.183826Z","iopub.execute_input":"2024-05-06T16:32:51.184196Z","iopub.status.idle":"2024-05-06T16:33:05.278795Z","shell.execute_reply.started":"2024-05-06T16:32:51.184166Z","shell.execute_reply":"2024-05-06T16:33:05.277724Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Extract texts and labels\ntexts = df['text'].tolist()\nlabels = df['generated'].values","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:33:23.990799Z","iopub.execute_input":"2024-05-06T16:33:23.991531Z","iopub.status.idle":"2024-05-06T16:33:24.021901Z","shell.execute_reply.started":"2024-05-06T16:33:23.991500Z","shell.execute_reply":"2024-05-06T16:33:24.020783Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:33:28.719744Z","iopub.execute_input":"2024-05-06T16:33:28.720487Z","iopub.status.idle":"2024-05-06T16:33:28.724600Z","shell.execute_reply.started":"2024-05-06T16:33:28.720453Z","shell.execute_reply":"2024-05-06T16:33:28.723596Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Splitting the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:33:31.182347Z","iopub.execute_input":"2024-05-06T16:33:31.182711Z","iopub.status.idle":"2024-05-06T16:33:31.532673Z","shell.execute_reply.started":"2024-05-06T16:33:31.182683Z","shell.execute_reply":"2024-05-06T16:33:31.531632Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from keras.src.legacy.preprocessing.text import Tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:33:35.902161Z","iopub.execute_input":"2024-05-06T16:33:35.902579Z","iopub.status.idle":"2024-05-06T16:33:35.906962Z","shell.execute_reply.started":"2024-05-06T16:33:35.902551Z","shell.execute_reply":"2024-05-06T16:33:35.905951Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Tokenizing the text data\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X_train)\nX_train_seq = tokenizer.texts_to_sequences(X_train)\nX_test_seq = tokenizer.texts_to_sequences(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:33:41.267778Z","iopub.execute_input":"2024-05-06T16:33:41.268718Z","iopub.status.idle":"2024-05-06T16:38:09.203524Z","shell.execute_reply.started":"2024-05-06T16:33:41.268671Z","shell.execute_reply":"2024-05-06T16:38:09.202615Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from keras.src.utils import pad_sequences","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:38:09.209806Z","iopub.execute_input":"2024-05-06T16:38:09.210078Z","iopub.status.idle":"2024-05-06T16:38:09.214659Z","shell.execute_reply.started":"2024-05-06T16:38:09.210053Z","shell.execute_reply":"2024-05-06T16:38:09.213777Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Padding sequences\nmax_len = max([len(seq) for seq in X_train_seq])\nX_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\nX_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:38:09.216090Z","iopub.execute_input":"2024-05-06T16:38:09.216385Z","iopub.status.idle":"2024-05-06T16:38:26.161858Z","shell.execute_reply.started":"2024-05-06T16:38:09.216361Z","shell.execute_reply":"2024-05-06T16:38:26.160999Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Building the CNN model\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Embedding(len(tokenizer.word_index)+1, 64, input_length=max_len),\n    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n    tf.keras.layers.GlobalMaxPooling1D(),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:31:50.288223Z","iopub.execute_input":"2024-05-06T16:31:50.288521Z","iopub.status.idle":"2024-05-06T16:31:50.298812Z","shell.execute_reply.started":"2024-05-06T16:31:50.288494Z","shell.execute_reply":"2024-05-06T16:31:50.297916Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Compiling the model\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:39:16.899212Z","iopub.execute_input":"2024-05-06T16:39:16.900188Z","iopub.status.idle":"2024-05-06T16:39:16.909145Z","shell.execute_reply.started":"2024-05-06T16:39:16.900153Z","shell.execute_reply":"2024-05-06T16:39:16.908336Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Training the model\nmodel.fit(X_train_pad, y_train, epochs=4, batch_size=4)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T16:39:21.107699Z","iopub.execute_input":"2024-05-06T16:39:21.108082Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/4\n\u001b[1m   24/85266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:47\u001b[0m 7ms/step - accuracy: 0.4890 - loss: 0.6931","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1715013574.469489     115 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m70647/85266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:36\u001b[0m 7ms/step - accuracy: 0.9803 - loss: 0.0507","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model\nmodel.save(\"cnn_model.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}